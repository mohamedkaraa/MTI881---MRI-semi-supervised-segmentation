{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchmetrics import Dice\n",
    "\n",
    "from progressBar import printProgressBar\n",
    "\n",
    "import medicalDataLoader\n",
    "import argparse\n",
    "from utils import *\n",
    "from losses import *\n",
    "from UNet_Base import *\n",
    "import random\n",
    "import torch\n",
    "import pdb\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from UNet_Attention import *\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "torch.manual_seed(420)\n",
    "random.seed(420)\n",
    "np.random.seed(420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_rampup(current, rampup_length):\n",
    "    \"\"\"Exponential rampup from https://arxiv.org/abs/1610.02242\"\"\"\n",
    "    if rampup_length == 0:\n",
    "        return 1.0\n",
    "    else:\n",
    "        current = np.clip(current, 0.0, rampup_length)\n",
    "        phase = 1.0 - current / rampup_length\n",
    "        return float(np.exp(-5.0 * phase * phase))\n",
    "\n",
    "def linear_rampup(current, rampup_length):\n",
    "    \"\"\"Linear rampup\"\"\"\n",
    "    assert current >= 0 and rampup_length >= 0\n",
    "    if current >= rampup_length:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return current / rampup_length\n",
    "\n",
    "\n",
    "def get_current_consistency_weight(epoch,consistency,consistency_rampup):\n",
    "    # Consistency ramp-up from https://arxiv.org/abs/1610.02242\n",
    "    return consistency * sigmoid_rampup(epoch, consistency_rampup)\n",
    "\n",
    "\n",
    "def update_ema_variables(model, ema_model, alpha, global_step):\n",
    "    # Use the true average until the exponential average is more correct\n",
    "    alpha = min(1 - 1 / (global_step + 1), alpha)\n",
    "    for ema_param, param in zip(ema_model.parameters(), model.parameters()):\n",
    "        ema_param.data.mul_(alpha).add_(1 - alpha, param.data)\n",
    "\n",
    "def create_model(num_classes,ema=False,n1=8):\n",
    "    # Network definition\n",
    "    model = UNet(num_classes=num_classes,n1=n1)\n",
    "    if ema:\n",
    "        for param in model.parameters():\n",
    "            param.detach_()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from torch.utils.data.sampler import Sampler\n",
    "\n",
    "class TwoStreamBatchSampler(Sampler):\n",
    "    \"\"\"Iterate two sets of indices\n",
    "    An 'epoch' is one iteration through the primary indices.\n",
    "    During the epoch, the secondary indices are iterated through\n",
    "    as many times as needed.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, primary_indices, secondary_indices, batch_size, secondary_batch_size):\n",
    "        self.primary_indices = primary_indices\n",
    "        self.secondary_indices = secondary_indices\n",
    "        self.secondary_batch_size = secondary_batch_size\n",
    "        self.primary_batch_size = batch_size - secondary_batch_size\n",
    "\n",
    "        assert len(self.primary_indices) >= self.primary_batch_size > 0\n",
    "        assert len(self.secondary_indices) >= self.secondary_batch_size > 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        primary_iter = iterate_once(self.primary_indices)\n",
    "        secondary_iter = iterate_eternally(self.secondary_indices)\n",
    "        return (\n",
    "            primary_batch + secondary_batch\n",
    "            for (primary_batch, secondary_batch) in zip(\n",
    "                grouper(primary_iter, self.primary_batch_size),\n",
    "                grouper(secondary_iter, self.secondary_batch_size),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.primary_indices) // self.primary_batch_size\n",
    "\n",
    "\n",
    "def iterate_once(iterable):\n",
    "    return np.random.permutation(iterable)\n",
    "\n",
    "\n",
    "def iterate_eternally(indices):\n",
    "    def infinite_shuffles():\n",
    "        while True:\n",
    "            yield np.random.permutation(indices)\n",
    "\n",
    "    return itertools.chain.from_iterable(infinite_shuffles())\n",
    "\n",
    "\n",
    "def grouper(iterable, n):\n",
    "    \"Collect data into fixed-length chunks or blocks\"\n",
    "    # grouper('ABCDEFG', 3) --> ABC DEF\"\n",
    "    args = [iter(iterable)] * n\n",
    "    return zip(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runTraining():\n",
    "    batch_size = 16\n",
    "    labeled_batch_size = 4\n",
    "    batch_size_val = 8\n",
    "    lr = 0.001     # Learning Rate \n",
    "    weight_decay = 1e-5\n",
    "    epochs = 200 # Number of epochs\n",
    "    consistency = 0.1\n",
    "    consistency_rampup = 200\n",
    "    ema_decay = 0.99\n",
    "\n",
    "    root_dir = './Data/'\n",
    "    train_img_path = os.path.join(root_dir, 'train', 'Img')\n",
    "    unlabeled_img_path = os.path.join(root_dir, 'train', 'Img-Unlabeled')\n",
    "\n",
    "    labeled_images = os.listdir(train_img_path)\n",
    "    unlabeled_images = os.listdir(unlabeled_img_path)\n",
    "    labeled_idx = list(range(0, len(labeled_images)))\n",
    "    unlabeled_idxs = list(range(len(labeled_images),len(labeled_images)+len(unlabeled_images)))\n",
    "    batch_sampler = TwoStreamBatchSampler(\n",
    "            labeled_idx, unlabeled_idxs, batch_size,batch_size-labeled_batch_size)\n",
    "    ## DEFINE THE TRANSFORMATIONS TO DO AND THE VARIABLES FOR TRAINING AND VALIDATION\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    mask_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    train_set_full = medicalDataLoader.MedicalImageDataset('train',\n",
    "                                                           'semi',\n",
    "                                                            root_dir,\n",
    "                                                            transform=transform,\n",
    "                                                            mask_transform=mask_transform,\n",
    "                                                            augment=False,\n",
    "                                                            equalize=False)\n",
    "\n",
    "    train_loader_full = DataLoader(train_set_full,\n",
    "                            batch_sampler=batch_sampler,\n",
    "                            worker_init_fn=np.random.seed(0),\n",
    "                            num_workers=0,\n",
    "                            shuffle=False)\n",
    "\n",
    "\n",
    "    val_set = medicalDataLoader.MedicalImageDataset('val',\n",
    "                                                    'semi',\n",
    "                                                root_dir,\n",
    "                                                transform=transform,\n",
    "                                                mask_transform=mask_transform,\n",
    "                                                equalize=False)\n",
    "\n",
    "    val_loader = DataLoader(val_set,\n",
    "                        batch_size=batch_size_val,\n",
    "                        worker_init_fn=np.random.seed(0),\n",
    "                        num_workers=0,\n",
    "                        shuffle=False)\n",
    "\n",
    "\n",
    "    ## INITIALIZE YOUR MODEL\n",
    "    num_classes = 4 # NUMBER OF CLASSES\n",
    "\n",
    "    print(\"~~~~~~~~~~~ Creating the UNet model ~~~~~~~~~~\")\n",
    "    modelName = 'UNet_Model'\n",
    "    print(\" Model Name: {}\".format(modelName))\n",
    "\n",
    "    ## CREATION OF YOUR MODEL\n",
    "    net = create_model(num_classes,n1=16)\n",
    "    ema_model = create_model(num_classes,ema=True,n1=16)\n",
    "    # net = AttU_Net(num_classes)\n",
    "\n",
    "    print(\"Total params: {0:,}\".format(sum(p.numel() for p in net.parameters() if p.requires_grad)))\n",
    "\n",
    "    # DEFINE YOUR OUTPUT COMPONENTS (e.g., SOFTMAX, LOSS FUNCTION, ETC)\n",
    "    softMax = torch.nn.Softmax(dim=1)\n",
    "    CE_loss = torch.nn.CrossEntropyLoss()\n",
    "    dice_loss = DiceLoss(num_classes)\n",
    "    ## PUT EVERYTHING IN GPU RESOURCES    \n",
    "    if torch.cuda.is_available():\n",
    "        net.cuda()\n",
    "        ema_model.cuda()\n",
    "        softMax.cuda()\n",
    "        CE_loss.cuda()\n",
    "        dice_loss.cuda()\n",
    "\n",
    "    ## DEFINE YOUR OPTIMIZER\n",
    "    optimizer = torch.optim.Adam(params=net.parameters(),lr=lr,weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "    ### To save statistics ####\n",
    "    lossTotalTraining = []\n",
    "    lossTotalValidation = []\n",
    "    Best_loss_val = 1000\n",
    "    BestEpoch = 0\n",
    "\n",
    "    directory = 'Results/Statistics/ssl/' + modelName\n",
    "\n",
    "    print(\"~~~~~~~~~~~ Starting the training ~~~~~~~~~~\")\n",
    "    if os.path.exists(directory)==False:\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    ## START THE TRAINING\n",
    "    num_iter = 0\n",
    "    ## FOR EACH EPOCH\n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "        lossEpoch = []\n",
    "        vlossEpoch = []\n",
    "        DSCEpoch = []\n",
    "        vDSCEpoch = []\n",
    "        ConsistEpoch = []\n",
    "        DSCEpoch_w = []\n",
    "        num_batches = len(train_loader_full)\n",
    "        v_num_batches = len(val_loader)\n",
    "        ########## Training ##########\n",
    "        net.train(True)\n",
    "        ## FOR EACH BATCH\n",
    "        for j, data in enumerate(train_loader_full):\n",
    "            ### Set to zero all the gradients\n",
    "            net.zero_grad()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            ## GET IMAGES, LABELS and IMG NAMES\n",
    "            images, labels, img_names = data\n",
    "            unlabeled_images = images[labeled_batch_size:]\n",
    "            noise = torch.clamp(torch.randn_like(\n",
    "                unlabeled_images) * 0.1, -0.2, 0.2)\n",
    "            ema_inputs = unlabeled_images + noise\n",
    "            ### From numpy to torch variables\n",
    "            labels = to_var(labels)\n",
    "            images = to_var(images)\n",
    "            ema_inputs = to_var(ema_inputs)\n",
    "\n",
    "            ################### Train ###################\n",
    "            #-- The CNN makes its predictions (forward pass)\n",
    "            net_predictions = net.forward(images)\n",
    "            with torch.no_grad():\n",
    "                ema_output = ema_model(ema_inputs)\n",
    "                ema_output_soft = torch.softmax(ema_output, dim=1)\n",
    "\n",
    "            #-- Compute the losses --#\n",
    "            # THIS FUNCTION IS TO CONVERT LABELS TO A FORMAT TO BE USED IN THIS CODE\n",
    "            segmentation_classes = getTargetSegmentation(labels)\n",
    "            # COMPUTE THE LOSS\n",
    "            CE_loss_value = CE_loss(softMax(net_predictions[:labeled_batch_size]),segmentation_classes[:labeled_batch_size])\n",
    "            dice_loss_value = dice_loss(softMax(net_predictions[:labeled_batch_size]),segmentation_classes[:labeled_batch_size].unsqueeze(1))\n",
    "           \n",
    "            # consistency loss\n",
    "            consistency_weight = get_current_consistency_weight(epoch,consistency,consistency_rampup)\n",
    "            if epoch < 20:\n",
    "                consistency_loss = torch.tensor(0.0)\n",
    "            else:\n",
    "                consistency_loss = torch.mean(\n",
    "                (softMax(net_predictions[labeled_batch_size:])-ema_output_soft)**2)\n",
    "            \n",
    "            lossTotal = 0.5*(CE_loss_value + dice_loss_value) + consistency_weight*consistency_loss\n",
    "            # DO THE STEPS FOR BACKPROP (two things to be done in pytorch)\n",
    "            lossTotal.backward()\n",
    "            optimizer.step()\n",
    "            update_ema_variables(net, ema_model, ema_decay, num_iter)\n",
    "            num_iter+=1\n",
    "            # THIS IS JUST TO VISUALIZE THE TRAINING \n",
    "            lossEpoch.append(CE_loss_value.cpu().data.numpy())\n",
    "            DSCEpoch.append(dice_loss_value.cpu().data.numpy())\n",
    "            ConsistEpoch.append(consistency_loss.cpu().data.numpy())\n",
    "            print\n",
    "            printProgressBar(j + 1, num_batches,\n",
    "                                prefix=\"[Training] Epoch: {} \".format(epoch),\n",
    "                                length=15,\n",
    "                                suffix=\" CE_Loss: {:.4f}, dice_loss:  {:.4f}, consist_loss:  {:.4f}\".format(CE_loss_value,dice_loss_value,consistency_loss))\n",
    "\n",
    "        lossEpoch = np.asarray(lossEpoch)\n",
    "        lossEpoch = lossEpoch.mean()\n",
    "        DSCEpoch = np.asarray(DSCEpoch)\n",
    "        DSCEpoch = DSCEpoch.mean()\n",
    "        ConsistEpoch = np.asarray(ConsistEpoch)\n",
    "        ConsistEpoch = ConsistEpoch.mean()\n",
    "        lossTotalTraining.append(lossEpoch+DSCEpoch+ConsistEpoch)\n",
    "        printProgressBar(num_batches, num_batches,\n",
    "                                done=\"[Training] Epoch: {}, LossG: {:.4f}\".format(epoch,lossEpoch+DSCEpoch+ConsistEpoch))\n",
    "        \n",
    "        ######### Validation ############\n",
    "        net.train(False)\n",
    "        for j, vdata in enumerate(val_loader):\n",
    "            vimages, vlabels, vimg_names = vdata\n",
    "            vlabels = to_var(vlabels)\n",
    "            vimages = to_var(vimages)\n",
    "            voutputs = net(vimages)\n",
    "            vsegmentation_classes = getTargetSegmentation(vlabels)\n",
    "            vloss = CE_loss(softMax(voutputs), vsegmentation_classes)\n",
    "            vdice = dice_loss(softMax(voutputs), vsegmentation_classes.unsqueeze(1))\n",
    "            vlossTotal = 0.5*(vloss + vdice)\n",
    "            vlossEpoch.append(vloss.cpu().data.numpy())\n",
    "            vDSCEpoch.append(vdice.cpu().data.numpy())\n",
    "            printProgressBar(j + 1, num_batches,\n",
    "                                prefix=\"[Validation] Epoch: {} \".format(epoch),\n",
    "                                length=15,\n",
    "                                suffix=\" CE_val_Loss: {:.4f}, dice_val_loss: {:.4f}\".format(vloss,vdice))\n",
    "            \n",
    "        vlossEpoch = np.asarray(vlossEpoch)\n",
    "        vlossEpoch = vlossEpoch.mean()\n",
    "        vDSCEpoch = np.asarray(vDSCEpoch)\n",
    "        vDSCEpoch = vDSCEpoch.mean()\n",
    "        lossTotalValidation.append(vlossEpoch+vDSCEpoch)\n",
    "        printProgressBar(v_num_batches, v_num_batches,\n",
    "                                done=\"[Validation] Epoch: {}, val_LossG: {:.4f}\".format(epoch,vlossEpoch+vDSCEpoch))\n",
    "\n",
    "\n",
    "\n",
    "        ## THIS IS HOW YOU WILL SAVE THE TRAINED MODELS AFTER EACH EPOCH. \n",
    "        ## WARNING!!!!! YOU DON'T WANT TO SAVE IT AT EACH EPOCH, BUT ONLY WHEN THE MODEL WORKS BEST ON THE VALIDATION SET!!\n",
    "        if not os.path.exists('./models/ssl/' + modelName):\n",
    "            os.makedirs('./models/ssl/' + modelName)\n",
    "        if  vlossEpoch < Best_loss_val:\n",
    "            Best_loss_val = vlossEpoch\n",
    "            BestEpoch = epoch\n",
    "            torch.save(net.state_dict(), './models/ssl/' + modelName + '/'  + str(BestEpoch)+'_Epoch')\n",
    "            \n",
    "        np.save(os.path.join(directory, 'TrainLosses.npy'), lossTotalTraining)\n",
    "        np.save(os.path.join(directory, 'ValLosses.npy'), lossTotalValidation)\n",
    "\n",
    "runTraining()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runTrainingTversky():\n",
    "    batch_size = 16\n",
    "    labeled_batch_size = 4\n",
    "    batch_size_val = 8\n",
    "    lr = 0.001     # Learning Rate\n",
    "    weight_decay = 1e-5\n",
    "    epochs = 220 # Number of epochs\n",
    "    consistency = 0.1\n",
    "    consistency_rampup = 200\n",
    "    alpha = 0.3# 0.5 0.3 0.8\n",
    "    beta = 0.8 # 0.5 0.8 0.3\n",
    "    ema_decay = 0.99\n",
    "\n",
    "    root_dir = './Data/'\n",
    "    train_img_path = os.path.join(root_dir, 'train', 'Img')\n",
    "    unlabeled_img_path = os.path.join(root_dir, 'train', 'Img-Unlabeled')\n",
    "\n",
    "    labeled_images = os.listdir(train_img_path)\n",
    "    unlabeled_images = os.listdir(unlabeled_img_path)\n",
    "    labeled_idx = list(range(0, len(labeled_images)))\n",
    "    unlabeled_idxs = list(range(len(labeled_images),len(labeled_images)+len(unlabeled_images)))\n",
    "    batch_sampler = TwoStreamBatchSampler(\n",
    "            labeled_idx, unlabeled_idxs, batch_size,batch_size-labeled_batch_size)\n",
    "    ## DEFINE THE TRANSFORMATIONS TO DO AND THE VARIABLES FOR TRAINING AND VALIDATION\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    mask_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    train_set_full = medicalDataLoader.MedicalImageDataset('train',\n",
    "                                                           'semi',\n",
    "                                                            root_dir,\n",
    "                                                            transform=transform,\n",
    "                                                            mask_transform=mask_transform,\n",
    "                                                            augment=False,\n",
    "                                                            equalize=False)\n",
    "\n",
    "    train_loader_full = DataLoader(train_set_full,\n",
    "                            batch_sampler=batch_sampler,\n",
    "                            worker_init_fn=np.random.seed(0),\n",
    "                            num_workers=0,\n",
    "                            shuffle=False)\n",
    "\n",
    "\n",
    "    val_set = medicalDataLoader.MedicalImageDataset('val',\n",
    "                                                    'semi',\n",
    "                                                root_dir,\n",
    "                                                transform=transform,\n",
    "                                                mask_transform=mask_transform,\n",
    "                                                equalize=False)\n",
    "\n",
    "    val_loader = DataLoader(val_set,\n",
    "                        batch_size=batch_size_val,\n",
    "                        worker_init_fn=np.random.seed(0),\n",
    "                        num_workers=0,\n",
    "                        shuffle=False)\n",
    "\n",
    "\n",
    "    ## INITIALIZE YOUR MODEL\n",
    "    num_classes = 4 # NUMBER OF CLASSES\n",
    "\n",
    "    print(\"~~~~~~~~~~~ Creating the UNet model ~~~~~~~~~~\")\n",
    "    modelName = 'UNet_Model_Tversky_lr'\n",
    "    print(\" Model Name: {}\".format(modelName))\n",
    "\n",
    "    ## CREATION OF YOUR MODEL\n",
    "    net = create_model(num_classes,n1=16)\n",
    "    ema_model = create_model(num_classes,ema=True,n1=16)\n",
    "    # net = AttU_Net(num_classes)\n",
    "\n",
    "    print(\"Total params: {0:,}\".format(sum(p.numel() for p in net.parameters() if p.requires_grad)))\n",
    "\n",
    "    # DEFINE YOUR OUTPUT COMPONENTS (e.g., SOFTMAX, LOSS FUNCTION, ETC)\n",
    "    softMax = torch.nn.Softmax(dim=1)\n",
    "    tversky = TverskyLoss(alpha=alpha,beta=beta,n_classes=num_classes)\n",
    "    ## PUT EVERYTHING IN GPU RESOURCES    \n",
    "    if torch.cuda.is_available():\n",
    "        net.cuda()\n",
    "        ema_model.cuda()\n",
    "        softMax.cuda()\n",
    "        tversky.cuda()\n",
    "\n",
    "    ## DEFINE YOUR OPTIMIZER\n",
    "    optimizer = torch.optim.Adam(params=net.parameters(),lr=lr,weight_decay=weight_decay)\n",
    "    lr_scheduler =  torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "\n",
    "    ### To save statistics ####\n",
    "    lossTotalTraining = []\n",
    "    lossTotalValidation = []\n",
    "    Best_loss_val = 1000\n",
    "    BestEpoch = 0\n",
    "\n",
    "    directory = 'Results/Statistics/ssl/' + modelName\n",
    "\n",
    "    print(\"~~~~~~~~~~~ Starting the training ~~~~~~~~~~\")\n",
    "    if os.path.exists(directory)==False:\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    ## START THE TRAINING\n",
    "    num_iter = 0\n",
    "    ## FOR EACH EPOCH\n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "        lossEpoch = []\n",
    "        ConsistEpoch = []\n",
    "        vlossEpoch = []\n",
    "\n",
    "        num_batches = len(train_loader_full)\n",
    "        v_num_batches = len(val_loader)\n",
    "        ########## Training ##########\n",
    "        net.train(True)\n",
    "        ## FOR EACH BATCH\n",
    "        for j, data in enumerate(train_loader_full):\n",
    "            ### Set to zero all the gradients\n",
    "            net.zero_grad()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            ## GET IMAGES, LABELS and IMG NAMES\n",
    "            images, labels, img_names = data\n",
    "            unlabeled_images = images[labeled_batch_size:]\n",
    "            noise = torch.clamp(torch.randn_like(\n",
    "                unlabeled_images) * 0.1, -0.2, 0.2)\n",
    "            ema_inputs = unlabeled_images + noise\n",
    "            ### From numpy to torch variables\n",
    "            labels = to_var(labels)\n",
    "            images = to_var(images)\n",
    "            ema_inputs = to_var(ema_inputs)\n",
    "\n",
    "            ################### Train ###################\n",
    "            #-- The CNN makes its predictions (forward pass)\n",
    "            net_predictions = net.forward(images)\n",
    "            with torch.no_grad():\n",
    "                ema_output = ema_model(ema_inputs)\n",
    "                ema_output_soft = torch.softmax(ema_output, dim=1)\n",
    "\n",
    "            #-- Compute the losses --#\n",
    "            # THIS FUNCTION IS TO CONVERT LABELS TO A FORMAT TO BE USED IN THIS CODE\n",
    "            segmentation_classes = getTargetSegmentation(labels)\n",
    "            # COMPUTE THE LOSS\n",
    "            Tversky_loss_value = tversky(softMax(net_predictions[:labeled_batch_size]),segmentation_classes[:labeled_batch_size])\n",
    "            # consistency loss\n",
    "            consistency_weight = get_current_consistency_weight(epoch,consistency,consistency_rampup)\n",
    "            if epoch < 20:\n",
    "                consistency_loss = torch.tensor(0.0)\n",
    "            else:\n",
    "                consistency_loss = torch.mean(\n",
    "                (softMax(net_predictions[labeled_batch_size:])-ema_output_soft)**2)\n",
    "            lossTotal =  Tversky_loss_value + consistency_weight*consistency_loss\n",
    "            # DO THE STEPS FOR BACKPROP (two things to be done in pytorch)\n",
    "            lossTotal.backward()\n",
    "            optimizer.step()\n",
    "            update_ema_variables(net, ema_model, ema_decay, num_iter)\n",
    "            num_iter+=1\n",
    "            # THIS IS JUST TO VISUALIZE THE TRAINING \n",
    "            lossEpoch.append(Tversky_loss_value.cpu().data.numpy())\n",
    "            ConsistEpoch.append(consistency_loss.cpu().data.numpy())\n",
    "            printProgressBar(j + 1, num_batches,\n",
    "                                prefix=\"[Training] Epoch: {} \".format(epoch),\n",
    "                                length=15,\n",
    "                                suffix=\" Tversky_Loss: {:.4f}, Conssistency_loss: {:.4f}\".format(Tversky_loss_value,consistency_loss))\n",
    "        \n",
    "        lossEpoch = np.asarray(lossEpoch)\n",
    "        lossEpoch = lossEpoch.mean()\n",
    "        ConsistEpoch = np.asarray(ConsistEpoch)\n",
    "        ConsistEpoch = ConsistEpoch.mean()\n",
    "        lossTotalMean = lossEpoch+ConsistEpoch\n",
    "        lossTotalTraining.append(lossTotalMean)\n",
    "        lr_scheduler.step(lossTotalMean)\n",
    "        printProgressBar(num_batches, num_batches,\n",
    "                                done=\"[Training] Epoch: {}, LossG: {:.4f}, lr: {:.8f} \".format(epoch,lossEpoch+ConsistEpoch,optimizer.param_groups[0][\"lr\"]))\n",
    "        \n",
    "        ######### Validation ############\n",
    "        net.train(False)\n",
    "        for j, vdata in enumerate(val_loader):\n",
    "            vimages, vlabels, vimg_names = vdata\n",
    "            vlabels = to_var(vlabels)\n",
    "            vimages = to_var(vimages)\n",
    "            voutputs = net(vimages)\n",
    "            vsegmentation_classes = getTargetSegmentation(vlabels)\n",
    "            vloss = tversky(softMax(voutputs), vsegmentation_classes)\n",
    "            vlossTotal = vloss\n",
    "            vlossEpoch.append(vloss.cpu().data.numpy())\n",
    "            printProgressBar(j + 1, num_batches,\n",
    "                                prefix=\"[Validation] Epoch: {} \".format(epoch),\n",
    "                                length=15,\n",
    "                                suffix=\" Tversky_val_Loss: {:.4f}\".format(vloss))\n",
    "            \n",
    "        vlossEpoch = np.asarray(vlossEpoch)\n",
    "        vlossEpoch = vlossEpoch.mean()\n",
    "        lossTotalValidation.append(vlossEpoch)\n",
    "        printProgressBar(v_num_batches, v_num_batches,\n",
    "                                done=\"[Validation] Epoch: {}, val_LossG: {:.4f}\".format(epoch,vlossEpoch))\n",
    "\n",
    "\n",
    "        ## THIS IS HOW YOU WILL SAVE THE TRAINED MODELS AFTER EACH EPOCH. \n",
    "        ## WARNING!!!!! YOU DON'T WANT TO SAVE IT AT EACH EPOCH, BUT ONLY WHEN THE MODEL WORKS BEST ON THE VALIDATION SET!!\n",
    "        if not os.path.exists('./models/ssl/' + modelName):\n",
    "            os.makedirs('./models/ssl/' + modelName)\n",
    "        if  vlossEpoch < Best_loss_val:\n",
    "            Best_loss_val = vlossEpoch\n",
    "            BestEpoch = epoch \n",
    "            torch.save(net.state_dict(), './models/ssl/' + modelName + '/'  + str(BestEpoch)+'_Epoch')\n",
    "            \n",
    "        np.save(os.path.join(directory, 'TrainLosses.npy'), lossTotalTraining)\n",
    "        np.save(os.path.join(directory, 'ValLosses.npy'), lossTotalValidation)\n",
    "\n",
    "runTrainingTversky()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = UNet(num_classes=4,n1=16) # attention unet\n",
    "net.load_state_dict(torch.load(r'models\\ssl\\UNet_Model_Tversky\\145_Epoch'))\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "    ])\n",
    "test_image = cv2.imread(r\"Data/val/Img/patient001_12_1.png\",0)\n",
    "test_image = transform(test_image).float()\n",
    "test_image = test_image.unsqueeze(0)\n",
    "test_image_label = cv2.imread(r\"Data/val/GT/patient001_12_1.png\",0)\n",
    "test_image_label = transform(test_image_label).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softMax = torch.nn.Softmax(dim=1)\n",
    "with torch.no_grad():\n",
    "    preds = softMax(net.forward(test_image))\n",
    "\n",
    "color_map = {0:0,1:1/3,2:2/3,3:1}\n",
    "preds = predToSegmentation(preds)\n",
    "seg = torch.zeros((256,256))\n",
    "for i in range(len(preds[0])):\n",
    "    for x in range(256):\n",
    "        for y in range(256):\n",
    "            if preds[0][i][x][y] == 1:\n",
    "                seg[x][y] = color_map[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(nrows=1,ncols=3,figsize=(15,15))\n",
    "axs[0].imshow(test_image.squeeze(0)[0],cmap='gray')\n",
    "axs[0].set_title('Image')\n",
    "axs[1].imshow(test_image_label[0],cmap='gray')\n",
    "axs[1].set_title('GT')\n",
    "axs[2].imshow(seg,cmap='gray')\n",
    "axs[2].set_title('prediction mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HD = computeHD(preds[0][1:],test_image_label[0])\n",
    "HD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DSC = computeDSC(preds[0][1:],test_image_label[0])\n",
    "DSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = np.load(r'Results\\Statistics\\ssl\\UNet_Model_Tversky_lr\\TrainLosses.npy')\n",
    "val_loss = np.load(r'Results\\Statistics\\ssl\\UNet_Model_Tversky_lr\\ValLosses.npy')\n",
    "plt.plot(train_loss,label='train loss')\n",
    "plt.plot(val_loss,label='val loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
